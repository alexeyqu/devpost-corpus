{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import defaultdict \n",
    "import nltk\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')  # Красивые графики\n",
    "plt.rcParams['figure.figsize'] = (15, 5)  # Размер картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../crawler/texts.csv',\n",
    "                   sep='\\n', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text\n",
      "0      Inspiration In the current media landscape, co...\n",
      "1      Inspiration I wanted to explore Mobile and Clo...\n",
      "2      My kid fell sick with the cold just before our...\n",
      "3      Intel Curie based wireless sensor network Intr...\n",
      "4      Inspiration bl What it does How I built it Cha...\n",
      "5      Challenge Create an app that contains all appl...\n",
      "6      Inspiration Previously, we (team behind StepSh...\n",
      "7      A Realtime Chat App for Educational Ecosystem....\n",
      "8      Who are we? Our team is made of two young moti...\n",
      "9      Inspiration To try and model the stock price m...\n",
      "10     Indra Indra is a personal assistant and a inte...\n",
      "11     Inspiration Ever happened to you that on red s...\n",
      "12     Inspiration Today's newspapers are filled with...\n",
      "13     Inspiration We want software engineering and p...\n",
      "14     Inspiration Games with split screen multiplaye...\n",
      "15     Online shopping is around for quit a long time...\n",
      "16     Inspiration The main inspiration behind this i...\n",
      "17     Inspiration In Africa, where I come from, inte...\n",
      "18     For a thorough review of our approach, solutio...\n",
      "19     Inspiration It is inspired by the data of the ...\n",
      "20     Inspiration In almost all automation which are...\n",
      "21     Experience is live at https://heytaxi.ma https...\n",
      "22     Inspiration Although there are so many documen...\n",
      "23     Inspiration From the touching scenes of seeing...\n",
      "24     Inspiration Indore is a place with lots of com...\n",
      "25     Inspiration While working with one of our cust...\n",
      "26     Inspiration A user wanted to sort all issue ty...\n",
      "27     Inspiration when the sponsor demo the speed of...\n",
      "28     Pneuma A project created during the 2015 PACT ...\n",
      "29     Inspiration As the cook of the household, I of...\n",
      "...                                                  ...\n",
      "98598  Inspiration This app is inspired by an actual ...\n",
      "98599  Lava Lamp: FlowOn Marching Cubes:\\nCreated a l...\n",
      "98600  Inspiration As engineering girls, we are usual...\n",
      "98601  As college students, we have to look at many, ...\n",
      "98602  Inspiration I am a part of a club at my high s...\n",
      "98603  Inspiration We were inspired by recent politic...\n",
      "98604  Inspiration I was learning to code and was att...\n",
      "98605  Summary With more than 3.8 million sports-rela...\n",
      "98606  Dismantling Data Tyranny With Health Data Demo...\n",
      "98607  Diabetes impacts the quality of life of over 3...\n",
      "98608  Inspiration We want to discourage packaging fo...\n",
      "98609  Project details: https://hackaday.io/project/1...\n",
      "98610  Project details: https://hackaday.io/project/9...\n",
      "98611  Project description here: https://hackaday.io/...\n",
      "98612  Inspiration Since our team is composed of a Cr...\n",
      "98613  Inspiration Bethaney and I love plants. Owning...\n",
      "98614  ჩვენი საიტის მიზანია დაეხმაროს ხალხს იპოვოს და...\n",
      "98615  We live in a world where healthcare is conside...\n",
      "98616  Inspiration I'm an economics and computer scie...\n",
      "98617  Inspiration When we are on our phone, we alway...\n",
      "98618  The idea for Smart Radiology and the first ste...\n",
      "98619  Projection mapping in dynamic fashion in holog...\n",
      "98620                        Fab Shop eCommerce Shop App\n",
      "98621  Inspiration Desktop widget for managing emails...\n",
      "98622  Incpetion Games Remember that crazy version of...\n",
      "98623  Inspiration The world needs more memes. We wan...\n",
      "98624  Inspiration Have you ever got to the end of a ...\n",
      "98625  Inspiration There are tonne of people online w...\n",
      "98626  There are 100 million active landmines in the ...\n",
      "98627  Inspiration We wanted to use Leap Motion for s...\n",
      "\n",
      "[98628 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Inspiration', 'In', 'the', 'current', 'media', 'landscape', 'control', 'over', 'distribution', 'has', 'become', 'almost', 'as', 'important', 'as', 'the', 'actual', 'creation', 'of', 'content', 'and', 'that', 'has', 'given', 'Facebook', 'a', 'huge', 'amount', 'of', 'power', 'The', 'impact', 'that', 'Facebook', 'newsfeed', 'has', 'in', 'the', 'formation', 'of', 'opinions', 'in', 'the', 'real', 'world', 'is', 'so', 'huge', 'that', 'it', 'potentially', 'affected', 'the', '2016', 'election', 'decisions', 'however', 'these', 'newsfeed', 'were', 'not', 'completely', 'accurate', 'Our', 'solution', 'FiB', 'because', 'With', '1', '5', 'Billion', 'Users', 'Every', 'Single', 'Tweak', 'in', 'an', 'Algorithm', 'Can', 'Make', 'a', 'Change', 'and', 'we', 'dont', 'stop', 'at', 'just', 'one', 'What', 'it', 'does', 'Our', 'algorithm', 'is', 'two', 'fold', 'as', 'follows', 'Content', 'consumption', 'Our', 'chrome', 'extension', 'goes', 'through', 'your', 'facebook', 'feed', 'in', 'real', 'time', 'as', 'you', 'browse', 'it', 'and', 'verifies', 'the', 'authenticity', 'of', 'posts', 'These', 'posts', 'can', 'be', 'status', 'updates', 'images', 'or', 'links', 'Our', 'backend', 'AI', 'checks', 'the', 'facts', 'within', 'these', 'posts', 'and', 'verifies', 'them', 'using', 'image', 'recognition', 'keyword', 'extraction', 'and', 'source', 'verification', 'and', 'a', 'twitter', 'search', 'to', 'verify', 'if', 'a', 'screenshot', 'of', 'a', 'twitter', 'update', 'posted', 'is', 'authentic', 'The', 'posts', 'then', 'are', 'visually', 'tagged', 'on', 'the', 'top', 'right', 'corner', 'in', 'accordance', 'with', 'their', 'trust', 'score', 'If', 'a', 'post', 'is', 'found', 'to', 'be', 'false', 'the', 'AI', 'tries', 'to', 'find', 'the', 'truth', 'and', 'shows', 'it', 'to', 'you', 'Content', 'consumption', 'Content', 'creation', 'Each', 'time', 'a', 'user', 'posts', 'shares', 'content', 'our', 'chat', 'bot', 'uses', 'a', 'webhook', 'to', 'get', 'a', 'call', 'This', 'chat', 'bot', 'then', 'uses', 'the', 'same', 'backend', 'AI', 'as', 'content', 'consumption', 'to', 'determine', 'if', 'the', 'new', 'post', 'by', 'the', 'user', 'contains', 'any', 'unverified', 'information', 'If', 'so', 'the', 'user', 'is', 'notified', 'and', 'can', 'choose', 'to', 'either', 'take', 'it', 'down', 'or', 'let', 'it', 'exist', 'Content', 'creation', 'How', 'we', 'built', 'it', 'Our', 'chrome', 'extension', 'is', 'built', 'using', 'javascript', 'that', 'uses', 'advanced', 'web', 'scraping', 'techniques', 'to', 'extract', 'links', 'posts', 'and', 'images', 'This', 'is', 'then', 'sent', 'to', 'an', 'AI', 'The', 'AI', 'is', 'a', 'collection', 'of', 'API', 'calls', 'that', 'we', 'collectively', 'process', 'to', 'produce', 'a', 'single', 'trust', 'factor', 'The', 'APIs', 'include', 'Microsoft', 's', 'cognitive', 'services', 'such', 'as', 'image', 'analysis', 'text', 'analysis', 'bing', 'web', 'search', 'Twitter', 's', 'search', 'API', 'and', 'Google', 's', 'Safe', 'Browsing', 'API', 'The', 'backend', 'is', 'written', 'in', 'Python', 'and', 'hosted', 'on', 'Heroku', 'The', 'chatbot', 'was', 'built', 'using', 'Facebook', 's', 'wit', 'ai', 'Challenges', 'we', 'ran', 'into', 'Web', 'scraping', 'Facebook', 'was', 'one', 'of', 'the', 'earliest', 'challenges', 'we', 'faced', 'Most', 'DOM', 'elements', 'in', 'Facebook', 'have', 'div', 'ids', 'that', 'constantly', 'change', 'making', 'them', 'difficult', 'to', 'keep', 'track', 'of', 'Another', 'challenge', 'was', 'building', 'an', 'AI', 'that', 'knows', 'the', 'difference', 'between', 'a', 'fact', 'and', 'an', 'opinion', 'so', 'that', 'we', 'do', 'not', 'flag', 'opinions', 'as', 'false', 'since', 'only', 'facts', 'can', 'be', 'false', 'Lastly', 'integrating', 'all', 'these', 'different', 'services', 'in', 'different', 'languages', 'together', 'using', 'a', 'single', 'web', 'server', 'was', 'a', 'huge', 'challenge', 'Accomplishments', 'that', 'we', 're', 'proud', 'of', 'All', 'of', 'us', 'were', 'new', 'to', 'Javascript', 'so', 'we', 'all', 'picked', 'up', 'a', 'new', 'language', 'this', 'weekend', 'We', 'are', 'proud', 'that', 'we', 'could', 'successfully', 'web', 'scrape', 'Facebook', 'which', 'uses', 'a', 'lot', 'of', 'techniques', 'to', 'prevent', 'people', 'from', 'doing', 'so', 'Finally', 'the', 'flawless', 'integration', 'we', 'were', 'able', 'to', 'create', 'between', 'these', 'different', 'services', 'really', 'made', 'us', 'feel', 'accomplished', 'What', 'we', 'learned', 'All', 'concepts', 'used', 'here', 'were', 'new', 'to', 'us', 'Two', 'people', 'on', 'our', 'time', 'are', 'first', 'time', 'hackathon', 'ers', 'and', 'learned', 'completely', 'new', 'technologies', 'in', 'the', 'span', 'of', '36hrs', 'We', 'learned', 'Javascript', 'Python', 'flask', 'servers', 'and', 'AI', 'services', 'What', 's', 'next', 'for', 'FiB', 'Hopefully', 'this', 'can', 'be', 'better', 'integrated', 'with', 'Facebook', 'and', 'then', 'be', 'adopted', 'by', 'other', 'social', 'media', 'platforms', 'to', 'make', 'sure', 'we', 'stop', 'believing', 'in', 'lies']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# print([text for text in df['text'][::10000]])# for word in tokenizer.tokenize(text)])\n",
    "print(tokenizer.tokenize(df['text'][0]))\n",
    "print(tokenizer.tokenize(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "words = []\n",
    "texts = []\n",
    "for text in df['text']:\n",
    "    try:\n",
    "        words += tokenizer.tokenize(text)\n",
    "    except:\n",
    "        print(text)\n",
    "        continue\n",
    "    texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98582\n",
      "1387.8383173398795 235.20463167718245\n"
     ]
    }
   ],
   "source": [
    "n_of_texts = len(texts)\n",
    "print(n_of_texts)\n",
    "mean_text_len_in_symbols = np.average(list(map(len, texts)))\n",
    "mean_text_len_in_words = np.average(list(map(len, [tokenizer.tokenize(text) for text in texts])))\n",
    "print(mean_text_len_in_symbols, mean_text_len_in_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 970113), ('to', 815649), ('and', 621710), ('a', 512381), ('of', 485416), ('we', 283364), ('for', 277672), ('in', 262755), ('that', 253250), ('it', 246986), ('is', 224686), ('with', 196736), ('I', 182395), ('on', 164782), ('What', 155747), ('We', 149023), ('s', 140434), ('can', 118182), ('be', 115470), ('as', 114281), ('you', 113958), ('The', 111397), ('are', 108217), ('our', 96512), ('an', 95161), ('into', 93532), ('this', 88723), ('from', 87566), ('was', 83616), ('by', 80875)]\n"
     ]
    }
   ],
   "source": [
    "print(word_counts.most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alexeyqu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenizer = nltk.data.load('nltk:tokenizers/punkt/russian.pickle')\n",
    "sents = [sent_tokenizer.tokenize(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.955052646527763\n"
     ]
    }
   ],
   "source": [
    "print(np.average(list(map(len, sents))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mipt",
   "language": "python",
   "name": "mipt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
